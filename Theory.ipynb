{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 42)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"intrusion-detection-theory/Train_data.csv\")\n",
    "lbl = LabelEncoder();\n",
    "df['protocol_type'] = lbl.fit_transform(df['protocol_type'])\n",
    "df.shape\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 40)\n"
     ]
    }
   ],
   "source": [
    "Y = df['xAttack']\n",
    "df.drop(['xAttack','num_outbound_cmds'],axis=1, inplace=True)\n",
    "print(df.shape)\n",
    "columns = df.columns\n",
    "X = df.iloc[:,0:40].values\n",
    "xmean = np.mean(X, axis=0)\n",
    "xstd = np.std(X,axis=0)\n",
    "# print(xmean)\n",
    "FX = []\n",
    "for index in X:\n",
    "    tmp = []\n",
    "    for i in range(len(index)):\n",
    "        tmp.append((index[i]-xmean[i])/xstd[i])\n",
    "    FX.append(tmp)\n",
    "X = np.array(FX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8495698 , -0.11068436, -0.03487308, ...,  0.56186162,\n",
       "         0.6185327 , -0.44680808],\n",
       "       [ 0.27017094,  1.2417322 , -0.16300179, ...,  0.03510949,\n",
       "         0.72343606, -1.19488482],\n",
       "       [ 4.12819764, -1.20715552,  0.05332764, ..., -0.27945382,\n",
       "        -0.0457868 , -0.2531399 ],\n",
       "       ...,\n",
       "       [-0.15960819, -0.42488558,  0.19789581, ..., -0.65675226,\n",
       "        -0.47285933, -0.7247115 ],\n",
       "       [ 4.06722071, -1.27695518, -0.01965612, ...,  0.23921812,\n",
       "         0.40620799,  0.07138056],\n",
       "       [-1.3581793 , -0.48372761,  0.02635176, ...,  0.38645703,\n",
       "         0.37672194, -0.17981096]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_pca = PCA(n_components=21)\n",
    "Y_sklearn = sklearn_pca.fit_transform(X)\n",
    "Y_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanvector = np.mean(X, axis=0)\n",
    "m = X.shape[0]-1;\n",
    "covariance = ((X - meanvector).T.dot((X - meanvector)))/m\n",
    "# covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalue, eigenvector = np.linalg.eig(covariance)\n",
    "eigen_val_vec = []\n",
    "# eigenvalue = np.abs(eigenvalue)\n",
    "for i in range(len(eigenvector)):\n",
    "    t = (eigenvalue[i],eigenvector[:,i])\n",
    "    eigen_val_vec.append(t)\n",
    "\n",
    "# eigenvector\n",
    "# eigenvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('duration', 7.700908616811359),\n",
       " ('protocol_type', 5.028775118413451),\n",
       " ('service', 2.823236887563214),\n",
       " ('flag', 2.2626637035654364),\n",
       " ('src_bytes', 1.956517812089621),\n",
       " ('dst_bytes', 1.857494291584614),\n",
       " ('land', 1.4233783473709745),\n",
       " ('wrong_fragment', 1.3022550311341843),\n",
       " ('urgent', 1.1846533326278497),\n",
       " ('dst_host_srv_count', 1.0906472645568495),\n",
       " ('dst_host_same_src_port_rate', 1.0336495732043829),\n",
       " ('dst_host_srv_diff_host_rate', 1.0070266448402927),\n",
       " ('dst_host_rerror_rate', 1.000424193473859),\n",
       " ('dst_host_srv_rerror_rate', 0.9999704791878697),\n",
       " ('dst_host_srv_serror_rate', 0.9900129483536815),\n",
       " ('dst_host_serror_rate', 0.9883910996776324),\n",
       " ('dst_host_diff_srv_rate', 0.9510913101409105),\n",
       " ('dst_host_same_srv_rate', 0.9021889753491834),\n",
       " ('dst_host_count', 0.7199273539897261),\n",
       " ('srv_diff_host_rate', 0.6733383267919277),\n",
       " ('diff_srv_rate', 0.6124309023640803),\n",
       " ('same_srv_rate', 0.6005807628444133),\n",
       " ('srv_rerror_rate', 0.4563156396411178),\n",
       " ('rerror_rate', 0.43556629829697047),\n",
       " ('srv_serror_rate', 0.4088269646900467),\n",
       " ('serror_rate', 0.34936775583854585),\n",
       " ('srv_count', 0.3146079056144496),\n",
       " ('count', 0.25993509075813465),\n",
       " ('is_host_login', 0.16891273594712447),\n",
       " ('is_guest_login', 0.13798262694473132),\n",
       " ('num_access_files', 0.09655544555002689),\n",
       " ('num_shells', 0.06689213962081741),\n",
       " ('num_file_creations', 0.06205177580774918),\n",
       " ('su_attempted', 0.043603257089417154),\n",
       " ('num_root', 0.03919598038620945),\n",
       " ('root_shell', 0.021173227628712078),\n",
       " ('num_compromised', 0.01612318128594421),\n",
       " ('logged_in', 0.0090067029435874),\n",
       " ('num_failed_logins', 0.004087470647663217),\n",
       " ('hot', 0.0005503562531133767)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "dictionary = dict(zip(columns, eigenvalue))\n",
    "dictionary = sorted(dictionary.items(), key=operator.itemgetter(1),reverse=True)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_val_vec.sort()\n",
    "eigen_val_vec.reverse()\n",
    "# eigen_val_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot = sum(eigenvalue)\n",
    "# eigenvalue = sorted(eigenvalue, reverse=True)\n",
    "pc = 0\n",
    "accuracy = 0\n",
    "lowerdimensionsmatrix = []\n",
    "for i in eigen_val_vec:\n",
    "    \n",
    "    pc = pc + 1\n",
    "    accuracy = accuracy + (i[0]/tot)*100\n",
    "    lowerdimensionsmatrix.append(i[1])\n",
    "    if accuracy>=90:\n",
    "        break\n",
    "\n",
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8495698 ,  0.11068437, -0.03487294, ...,  0.56187986,\n",
       "        -0.61860963, -0.44668091],\n",
       "       [ 0.27017095, -1.24173227, -0.16300186, ...,  0.03527588,\n",
       "        -0.72377819, -1.19470078],\n",
       "       [ 4.12819764,  1.20715551,  0.05332763, ..., -0.27942945,\n",
       "         0.04573617, -0.25311015],\n",
       "       ...,\n",
       "       [-0.15960819,  0.4248856 ,  0.19789577, ..., -0.6568251 ,\n",
       "         0.47301959, -0.72483127],\n",
       "       [ 4.06722071,  1.27695517, -0.01965613, ...,  0.2392379 ,\n",
       "        -0.40624852,  0.07140205],\n",
       "       [-1.35817931,  0.48372761,  0.02635174, ...,  0.3864343 ,\n",
       "        -0.37667482, -0.1798448 ]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowerdimensionsmatrix = np.array(lowerdimensionsmatrix)\n",
    "lowerdimensionsmatrix = lowerdimensionsmatrix.T\n",
    "X_low = X.dot(lowerdimensionsmatrix)\n",
    "X_low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why PCA not applicable on the above dataset ?\n",
    "* PCA is desinged for continuous variables. It tries to minimize variance (Squared deviations). The concept of squared deviations breaks down when you have binary variables.\n",
    "\n",
    "\n",
    "* In our case total 44 features are there and among them more than half features are categorical (i.e 23 features are categorical).Since they are categorical they have very small variance(small range cover) and hence if we apply PCA on them then most of the categorical features will be eliminated.Because continuous features are dominated more.One more thing, Taking projection of categorical data does not make sense because individual numeric values of categorical data does not convey anything.In the above example i have applied PCA on data and most of the categorical data has been elimintaed except 1 or 2.In such case we may not able to predict effictively. So if more number of features are categorical then PCA cannot be applicable. For categorical data we can use non linear pca."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
